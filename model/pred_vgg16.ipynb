{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9c89d35a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from glob import glob\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "import torch.utils.data as data\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import image as mpimg\n",
    "import time\n",
    "import requests\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9b96aac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "VGG_types = {\n",
    "    \"VGG11\": [64, \"M\", 128, \"M\", 256, 256, \"M\", 512, 512, \"M\", 512, 512, \"M\"],\n",
    "    \"VGG13\": [64, 64, \"M\", 128, 128, \"M\", 256, 256, \"M\", 512, 512, \"M\", 512, 512, \"M\"],\n",
    "    \"VGG16\": [64, 64, \"M\", 128, 128, \"M\", 256, 256, 256, \"M\", 512, 512, 512, \"M\", 512, 512, 512, \"M\"],\n",
    "    \"VGG19\": [64, 64, \"M\", 128, 128, \"M\", 256, 256, 256, 256,\"M\", 512, 512, 512, 512,\"M\", 512, 512, 512, 512,\"M\"]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c0bef589",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VGG_net(nn.Module):\n",
    "    def __init__(self, in_channels=3, num_classes=1000):\n",
    "        super(VGG_net, self).__init__()\n",
    "        self.in_channels = in_channels\n",
    "        self.conv_layers = self.create_conv_layers(VGG_types[\"VGG16\"])\n",
    "\n",
    "        self.fcs = nn.Sequential(\n",
    "            nn.Linear(512 * 7 * 7, 4096),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.Linear(4096, 4096),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.Linear(4096, num_classes),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv_layers(x)\n",
    "        x = x.reshape(x.shape[0], -1)\n",
    "        x = self.fcs(x)\n",
    "        return x\n",
    "\n",
    "    def create_conv_layers(self, architecture):\n",
    "        layers = []\n",
    "        in_channels = self.in_channels\n",
    "\n",
    "        for x in architecture:\n",
    "            if type(x) == int:\n",
    "                out_channels = x\n",
    "\n",
    "                layers += [\n",
    "                    nn.Conv2d(\n",
    "                        in_channels=in_channels,\n",
    "                        out_channels=out_channels,\n",
    "                        kernel_size=(3, 3),\n",
    "                        stride=(1, 1),\n",
    "                        padding=(1, 1),\n",
    "                    ),\n",
    "                    nn.BatchNorm2d(x),\n",
    "                    nn.ReLU(),\n",
    "                ]\n",
    "                in_channels = x\n",
    "            elif x == \"M\":\n",
    "                layers += [nn.MaxPool2d(kernel_size=(2, 2), stride=(2, 2))]\n",
    "\n",
    "        return nn.Sequential(*layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "99a51d2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda:0')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aba6e906",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=VGG_net(in_channels=3, num_classes=2).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "94bb36c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VGG_net(\n",
       "  (conv_layers): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): ReLU()\n",
       "    (6): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
       "    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (9): ReLU()\n",
       "    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (12): ReLU()\n",
       "    (13): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
       "    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (16): ReLU()\n",
       "    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (19): ReLU()\n",
       "    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (22): ReLU()\n",
       "    (23): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
       "    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (26): ReLU()\n",
       "    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (29): ReLU()\n",
       "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (32): ReLU()\n",
       "    (33): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
       "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (36): ReLU()\n",
       "    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (39): ReLU()\n",
       "    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (42): ReLU()\n",
       "    (43): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (fcs): Sequential(\n",
       "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Dropout(p=0.5, inplace=False)\n",
       "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "    (4): ReLU()\n",
       "    (5): Dropout(p=0.5, inplace=False)\n",
       "    (6): Linear(in_features=4096, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PATH = 'E:\\Anaconda\\envs\\dataset\\cifar_net.pth'\n",
    "model.load_state_dict(torch.load(PATH))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "04a92189",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "# import requests\n",
    "\n",
    "# URL = \"http://localhost:8080/report/get\"\n",
    "# r = requests.get(url = URL)\n",
    "# data = r.json()\n",
    "# print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "c67640b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(168, 299, 3)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# image = mpimg.imread(\"E:/coll project/my_pro/backend/frontend/public/uploads/\"+data[\"image\"])\n",
    "# image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "1bfe0295",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_dir = \"E:/coll project/my_pro/backend/frontend/public/uploads/\"+data[\"image\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1628c1e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRANSFORM_IMG =transforms.Compose([\n",
    "#     transforms.Lambda(crop224),\n",
    "    transforms.Resize((224,224)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "#     transforms.Normalize(mean=[0.5,0.5,0.5],\n",
    "#                          std=[0.5,0.5,0.5])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "e15a5529",
   "metadata": {},
   "outputs": [],
   "source": [
    "# c_img=Image.fromarray(np.uint8(image)).convert('RGB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "695b2b69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 224, 224])"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ct_img=TRANSFORM_IMG(c_img).to(device)\n",
    "# ct_img\n",
    "# # plt.imshow(ct_img.permute(1,2,0))\n",
    "# # plt.show()\n",
    "# ct_img=ct_img.reshape(1, 3, 224, 224)\n",
    "# ct_img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "eeced237",
   "metadata": {},
   "outputs": [],
   "source": [
    "# outputs = model(ct_img)\n",
    "\n",
    "# _, predicted = torch.max(outputs.data, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c91594ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes= ('Monkeypox','Normal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "6ce2ba47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Monkeypox'"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# classes[predicted]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "2adf2da9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# URL = \"http://localhost:8080/report/updateName/\"+data['_id']+'/'+classes[predicted]\n",
    "# r = requests.get(url = URL,params = PARAMS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3f9a7e37",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_12348\\2672376592.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     16\u001b[0m         \u001b[0mr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mURL\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m     \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m6\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    URL = \"http://localhost:8080/report/get\"\n",
    "    r = requests.get(url = URL)\n",
    "    data = r.json()\n",
    "\n",
    "  \n",
    "    if(data != None):\n",
    "        print(data)\n",
    "        image = mpimg.imread(\"E:/coll project/my_pro/backend/frontend/public/uploads/\"+data[\"image\"])\n",
    "        c_img=Image.fromarray(np.uint8(image)).convert('RGB')\n",
    "        ct_img=TRANSFORM_IMG(c_img).to(device)\n",
    "        ct_img=ct_img.reshape(1, 3, 224, 224)\n",
    "        outputs = model(ct_img)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        URL = \"http://localhost:8080/report/updateName/\"+data['_id']+'/'+classes[predicted]\n",
    "        r = requests.get(url = URL)\n",
    "    \n",
    "    time.sleep(6)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c0d30bc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
